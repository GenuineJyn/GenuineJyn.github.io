# sync.Pool源码剖析

在Golang日常开发中，goroutine和自动的GC提供了很多遍历，但是GC也带来了运行时开销，在高并发以及对性能要求比较高的情况这种开销的影响也就越发的显现出来。因此，在Golang的早期版本就意识到了这个问题，并在1.3中引入了sync.Pool, 以达到复用对象和减少GC的负担，本文会对sync.Pool进行源码剖析，虽然整个源码不到300行，但其中的内容实在不少。在阅读源码网上查询问题过程中发现runtime的很多问题都没有得到解答，本文同样也尝试进行适当的扩展，并且也留下了几个问题需要后续补充。

## 1.前提知识
在窥探sync.Pool需要把一些前提的准备知识现在这里简单介绍一下，以便能够更好理解sync.Pool。每一项详细信息可自行去进行扩展，当然本文最后也列举了部分参考链接。

### 1.1 Go scheduler

golang实现了一个M:N的协程调度模型：M-P-G模型，如下图所示。
![RedirectIterator](https://raw.githubusercontent.com/GenuineJyn/GenuineJyn.github.io/master/pictures/mpg.png)

其中：

* G：就是我们非常熟悉的goroutine，存储了goroutine执行的stack等等状态；
* P： 逻辑Processor，P的个数由GOMAXPROCS设定，G只有先被P选中后才能最后被真正调度；
* M：Machine，“物理Processor”，可以理解为操作系统用户态线程，P绑定M后被调度执行；
* LRQ： P的RunQueue，每次从自己的LRQ选择一个G执行；
* GRQ： 全局的RunQueue，防止M饿死，特定情况下会有进程负责把GRQ转移到LRQ进行调度执行；

### 1.2 go:linkname
`//go:linkname`是一种编译器指令（[Complier Directives](https://golang.org/cmd/compile/)），被用来把私有方法或者变量暴露出去，指引Go编译器编译找到具体实现的函数代码，类似C/C++，可以多处声明，而只在一个文件中定义实现。

```
//go:linkname localname importpath.name
```
The //go:linkname directive instructs the compiler to use “importpath.name” as the object file symbol name for the variable or function declared as “localname” in the source code.

这里介绍一下，便于在runtime源码中找到具体实现，例如sync.Pool中的：

```
// file: runtime/proc.go
5085 //go:linkname sync_runtime_procPin sync.runtime_procPin
```
在sync中声明的runtime_procPin实现是sync_runtime_procPin。

### 1.3 noCopy
golang中没有从语言层面提供禁止拷贝的方式，因此仅提供了通过go vet进行静态代码检测的方式来检测noCopy，noCopy实现了sync.Locker interface。
```
 // file: sync/cond.go
 89 // noCopy may be embedded into structs which must not be copied
 90 // after the first use.
 91 //
 92 // See https://golang.org/issues/8005#issuecomment-190753527
 93 // for details.
 94 type noCopy struct{}
 95
 96 // Lock is a no-op used by -copylocks checker from `go vet`.
 97 func (*noCopy) Lock()   {}
 98 func (*noCopy) Unlock() {}
```
注释中提供了相关的issue的内容，可以参考一下。如果自己定义的结构体不希望被copy，则可以把类似的内容添加自己的实现文件中，go vet依然可以使用，但是需要注意：

* 1.noCopy仅仅是一种禁止拷贝宣言，并不影响编译和运行，仅对静态检测有效，因此看到noCopy，使用者应该准守禁止拷贝的语义；
* 2.指针传递并没有任何问题, 因为本质上没有进行copy操作；

举例如下：

```
  1 package main
  2
  3 import "fmt"
  4
  5 type noCopy struct{}
  6
  7 func (*noCopy) Lock()   {}
  8 func (*noCopy) Unlock() {}
  9
 10 type My struct {
 11     noCopy noCopy
 12     i      int
 13 }
 14
 15 func main() {
 16     m := My{i: 2019}
 17
 18     var b My = m
 19     c := &m   // <---- 这里没有任何问题
 20
 21     fmt.Println(b)
 22     fmt.Println(c)
 23 }
```
go vet执行结果如下：

```
# command-line-arguments
./nocopy.go:18:13: variable declaration copies lock value to b: command-line-arguments.My contains command-line-arguments.noCopy
./nocopy.go:21:14: call of fmt.Println copies lock value: command-line-arguments.My contains command-line-arguments.noCopy
```


### 1.4 Race Dectector & memory order
在golang的工具链中集成了RaceDectector，当使用go进行build/run/test的可以通过`-race`打开，编译器会额外编译部分代码用于记录内存被访问的情况，用于检测Race Conditions，Race Conditions就是对共享资源不做同步控制，由于访问顺序的不确定导致出现不符合预期或严重的后果，具体内容可以在参考连接中找到，在golang并发相关代码中都会出现大量race的内容，sync.Pool中也自然存在，后续介绍代码的时候不再关注Race的内容，要实现Dectecotr就需要对内存一致性有一定的要求，Golang的[内存模型](https://golang.org/ref/mem)也是需要相关语义才能建立`happens-before`的，对Golang这部分内容介绍不多，网上也各种问题满天飞。这里简单介绍一下Moden C++（C++11及以后的C++）引入的memory order，golang借鉴了Modern C++的这部分内容。
在golang的源码internal/race/race.go实现Acquire/Release/ReleaseMerge实现的内容都引用了runtime中(runtime/race.go)对应的RaceAcquire/RaceRelease/RaceReleaseMerge

```
 35 // RaceAcquire is equivalent to atomic_load(memory_order_acquire).
	......
 56 // In terms of the C memory model, RaceReleaseMerge is equivalent to
 57 // atomic_exchange(memory_order_release).
```
另外，sync.Pool中也使用了atomic，也有Release/Require的相关语义，这里还是介绍一下相关内容。

在Modern C++ <atomic>中提供了原子操作，也引入的std::thread，多线程间不同步+可能的编译器优化调整执行顺序等多种原因都会造成乱序, 就需要对线程间的内存一致性提供支持，使用atomic时要结合不同的memory order，Modern C++中提供了6种memory order，参见参考文档, 这里简单介绍一下：`memory_order_acquire`和`memory_order_release`,节选部分说明如下：。

```
memory_order_acquire: A load operation with this memory order performs the acquire operation on the affected memory location: no reads or writes in the current thread can be reordered before this load. 

memory_order_release: A store operation with this memory order performs the release operation: no reads or writes in the current thread can be reordered after this store. 

If an atomic store in thread A is tagged memory_order_release and an atomic load in thread B from the same variable is tagged memory_order_acquire, all memory writes (non-atomic and relaxed atomic) that happened-before the atomic store from the point of view of thread A, become visible side-effects in thread B. That is, once the atomic load is completed, thread B is guaranteed to see everything thread A wrote to memory.

The synchronization is established only between the threads releasing and acquiring the same atomic variable. Other threads can see different order of memory accesses than either or both of the synchronized threads.
```
理解一下Acquire和Release语义：
Acquire：被Acquire修饰的读内存操作，能够防止任何读写操作重排到它的前面。
Release：被Release修饰的写内存操作，能够防止任何读写操作重排到它的后面。
什么意思呢？ Acquire-Release之间建立一种`synchronzie-with`关系，单个Acquire和Release对执行序列进行约束（sequenced-before），举个生产者消费者的例子，伪代码如下：

```
// 临界区资源
std::vector<int> shared_products;
std::atomic<bool> produced;
std::atomic<bool> can_consumed;

ProducerThread:
	shared_products = {1, 2, 3};		// STEP1
	produced.store(true, std::memory_order_release); // STEP2
	
DeliverThread:
	while (!produced.load(std::memory_order_acquire));  // STEP3 注意这里有空语句
	can_consumed.store(true, std::memory_order_release); // STEP4
		
ConsumerThread:
	while (!can_consumed.load(std::memory_order_acquire)); // STEP5
	shared_products[0] = 0; // STEP6
```
STEP1 `sequenced-before` STEP2  不然可能是乱序的，例如先store后赋值了

STEP3 `sequenced-before` STEP4

STEP5 `sequenced-before` STEP6

STEP2 `synchronize-with` STEP3  STEP2之前的赋值（副作用）操作对STEP3之后可见

STEP4 `synchronize-with` STEP5  STEP4之前的读取操作对STEP5之后可见，这说明Acquire-Release是可传递的。

`sequenced-before`,`synchronize-with`以及`Inter-thread happens-before`，`Happens-before`可以在参考文档中`cppreference.com`相关链接中找到。举例中即满足`Inter-thread happens-before`也满足`Happens-before`, 如下图所示。

[require/release](https://raw.githubusercontent.com/GenuineJyn/GenuineJyn.github.io/master/pictures/require_release.png)

### 1.5 False Sharing
在日常多线程并发实践中，False-sharing是经常会遇到的问题，通常的做法也是使用padding来合理的规避这种严重影响性能的问题，这里简单的介绍一下。在现有CUP+超线程硬件基础上，整体实际上是一个多core + 超线程 + 多级cache的架构，整个结构如下图（图片来自大神Scott Meyers的文档[CPU Caches and Why You Care](https://www.aristeia.com/TalkNotes/codedive-CPUCachesHandouts.pdf)）。

[false-sharing-meyers](https://raw.githubusercontent.com/GenuineJyn/GenuineJyn.github.io/master/pictures/meyers_cup.png)


所有core需要共用L3 Cache，另外多级Cache是以Cache Line为单位进行存储的，主流Cache Line基本上都是64Byte，当多线程修改落在同一个CacheLine的不同内容的时候，无意中影响了彼此的性能。由于需要在L3 Cache中进行Cache同步或者从内存重新Load，这样就严重影响性能，看如下具体例子：

```
	struct XXXData {
		uint32_t A;
		uint32_t B;
	};

```
现有两个线程分别异步的更新A，B的值，如下图所示。

[false-sharing](https://raw.githubusercontent.com/GenuineJyn/GenuineJyn.github.io/master/pictures/false-sharing.png)

如果Core1获得了CacheLine的所有权进行更新A，则Core2就需要是对应的CacheLine失效，从L3重新加载，反之也是一样的。这样Core1和Core2就需要不断的来来回回的经过L3缓存，这严重的影响了性能。因此解决问题的办法就是："Magic cache line padding"

```
	struct XXXData {
		uint32_t A;
		uint64_t padding[8];
		uint32_t B;
	};
```
这样就可保证A，B落在同一个Cache Line中，从而避免因共享而产生的问题：false-sharing.
我们使用golang的代码来做一下BenchMark，看一下影响。

```
  1 package main
  2
  3 import (
  4     "runtime"
  5     "sync"
  6     "sync/atomic"
  7     "testing"
  8 )
  9
 10 type Increaser interface {
 11     IncreaseA()
 12     IncreaseB()
 13 }
 14
 15 type NoPad struct {
 16     a uint64
 17     b uint64
 18 }
 19
 20 func (np *NoPad) IncreaseA() {
 21     atomic.AddUint64(&np.a, 1)
 22 }
 23
 24 func (np *NoPad) IncreaseB() {
 25     atomic.AddUint64(&np.b, 1)
 26 }
 27
 28 type Pad struct {
 29     a         uint64
 30     _padding1 [8]uint64
 31     b         uint64
 32 }
 33
 34 func (p *Pad) IncreaseA() {
 35     atomic.AddUint64(&p.a, 1)
 36 }
 37
 38 func (p *Pad) IncreaseB() {
 39     atomic.AddUint64(&p.b, 1)
 40 }
 41
 42 func ConcurrencyIncrease(incr Increaser) {
 43     runtime.GOMAXPROCS(4)
 44     numberOfG := 16
 45     addTimes := 65536
 46     var wg sync.WaitGroup
 47     wg.Add(numberOfG * 2)
 48     for i := 0; i < numberOfG; i++ {
 49         go func() {
 50             for j := 0; j < addTimes; j++ {
 51                 incr.IncreaseA()
 52             }
 53             wg.Done()
 54         }()
 55     }
 56
 57     for i := 0; i < numberOfG; i++ {
 58         go func() {
 59             for j := 0; j < addTimes; j++ {
 60                 incr.IncreaseB()
 61             }
 62             wg.Done()
 63         }()
 64     }
 65     wg.Wait()
 66 }
 67
 68 func BenchmarkNoPadding(b *testing.B) {
 69     np := &NoPad{}
 70     b.ResetTimer()
 71     for n := 0; n < b.N; n++ {
 72         ConcurrencyIncrease(np)
 73     }
 74 }
 75
 76 func BenchmarkPadding(b *testing.B) {
 77     p := &Pad{}
 78     b.ResetTimer()
 79     for n := 0; n < b.N; n++ {
 80         ConcurrencyIncrease(p)
 81     }
 82 }
```
Benchmark结果如下：

```
go test -bench=. -count=3
-----------------------------------------------------------
goos: linux
goarch: amd64
pkg: example/false_sharing
BenchmarkNoPadding-4   	      30	  48139772 ns/op
BenchmarkNoPadding-4   	      30	  47796285 ns/op
BenchmarkNoPadding-4   	      30	  48003415 ns/op
BenchmarkPadding-4     	      50	  25974111 ns/op
BenchmarkPadding-4     	     100	  33791999 ns/op
BenchmarkPadding-4     	      50	  29254085 ns/op
PASS
ok  	example/false_sharing	10.690s
```
从Benchmark结果上看，影响还是比较明显的。


## 2. Sync.Pool实现
总算可以看看sync.Pool的实现了（一声长叹^-^）。

### 2.1 底层数据结构

```
 43 // A Pool must not be copied after first use.
 44 type Pool struct {
 45     noCopy noCopy
 46
 47     local     unsafe.Pointer // local fixed-size per-P pool, actual type is [P]poolLocal
 48     localSize uintptr        // size of the local array
 49
 50     // New optionally specifies a function to generate
 51     // a value when Get would otherwise return nil.
 52     // It may not be changed concurrently with calls to Get.
 53     New func() interface{}
 54 }
 55
 56 // Local per-P Pool appendix.
 57 type poolLocalInternal struct {
 58     private interface{}   // Can be used only by the respective P.
 59     shared  []interface{} // Can be used by any P.
 60     Mutex                 // Protects shared.
 61 }
 62
 63 type poolLocal struct {
 64     poolLocalInternal
 65
 66     // Prevents false sharing on widespread platforms with
 67     // 128 mod (cache line size) = 0 .
 68     pad [128 - unsafe.Sizeof(poolLocalInternal{})%128]byte
 69 }
 
 243     allPools   []*Pool
```
 
 几个重要数据结构：Pool，poolLocalInternal，poolLocal，allPools，先看看poolLocalInternal和poolLocal。poolLocal组合poolLocalInternal，并采用padding来避免false sharing，**为什么需要填充呢？**
 
unsafe.Sizeof(poolLocalInternal{})在64位CPU上大小是48个字节：interface{}：16个字节， []interface{}(slice):24个字节和Mutex(2个int32）：8个字节，如之前说到的一般CacheLine是64Byte，因此肯定需要Padding避免false-sharing，代码这里考虑到通用性，直接保证了128Byte，一个poolLocal独占一个CacheLine，接下来继续来看看到底是怎样组织的数据的。
 
### 2.2 sync::Get/New
Get的代码如下，先分别来看看3个重要的实现【标注点1】【标注点2】【标注点3】，最后再总结一下。

```
116 // Get selects an arbitrary item from the Pool, removes it from the
117 // Pool, and returns it to the caller.
118 // Get may choose to ignore the pool and treat it as empty.
119 // Callers should not assume any relation between values passed to Put and
120 // the values returned by Get.
121 //
122 // If Get would otherwise return nil and p.New is non-nil, Get returns
123 // the result of calling p.New.
124 func (p *Pool) Get() interface{} {
125     if race.Enabled {
126         race.Disable()
127     }
128     l := p.pin()     // 【标注点1】
129     x := l.private
130     l.private = nil
131     runtime_procUnpin() // 【标注点2】
132     if x == nil {
133         l.Lock()
134         last := len(l.shared) - 1
135         if last >= 0 {
136             x = l.shared[last]
137             l.shared = l.shared[:last]
138         }
139         l.Unlock()
140         if x == nil {
141             x = p.getSlow()
142         }
143     }
144     if race.Enabled {
145         race.Enable()
146         if x != nil {
147             race.Acquire(poolRaceAddr(x))
148         }
149     }
150     if x == nil && p.New != nil {
151         x = p.New() 【标注点3】
152     }
153     return x
154 }
```
先看【标注点3】代码，刚开始的时候都是nil，肯定需要从这里返回一个，因此创建Pool需要初始化New，否则会返回nil。

#### 2.2.1 runtime_procPin/runtime_procUnpin
接下来在看【标注点2】，先找到runtime_procPin/runtime_procUnpin的实现代码，如下。
```
// file: runtime/proc.go
5085 //go:linkname sync_runtime_procPin sync.runtime_procPin
5086 //go:nosplit
5087 func sync_runtime_procPin() int {
5088     return procPin()
5089 }
5090
5091 //go:linkname sync_runtime_procUnpin sync.runtime_procUnpin
5092 //go:nosplit
5093 func sync_runtime_procUnpin() {
5094     procUnpin()
5095 }


5070 //go:nosplit
5071 func procPin() int {
5072     _g_ := getg()
5073     mp := _g_.m
5074
5075     mp.locks++  //【标注点3】
5076     return int(mp.p.ptr().id)
5077 }
5078
5079 //go:nosplit
5080 func procUnpin() {
5081     _g_ := getg()
5082     _g_.m.locks--
5083 }
```
procPin获取当前运行的g，并查到g在哪个m上运行，把mp.locks++（不可被抢占），并返回绑在m上的p的id，而procUnpin则_g_.m.locks--, m.locks holding操作可以阻止GC。

#### 2.2.2 Pool::pin()
接下来看看pin的实现，代码如下。

```
178 // pin pins the current goroutine to P, disables preemption and returns poolLocal pool for the P.
179 // Caller must call runtime_procUnpin() when done with the pool.
180 func (p *Pool) pin() *poolLocal {
181     pid := runtime_procPin() 【标注点2】
182     // In pinSlow we store to localSize and then to local, here we load in opposite order.
183     // Since we've disabled preemption, GC cannot happen in between.
184     // Thus here we must observe local at least as large localSize.
185     // We can observe a newer/larger local, it is fine (we must observe its zero-initialized-ness).
186     s := atomic.LoadUintptr(&p.localSize) // load-acquire
187     l := p.local                          // load-consume
188     if uintptr(pid) < s {
189         return indexLocal(l, pid)
190     }
191     return p.pinSlow()
192 }
193
194 func (p *Pool) pinSlow() *poolLocal {
195     // Retry under the mutex.
196     // Can not lock the mutex while pinned.
197     runtime_procUnpin()
198     allPoolsMu.Lock()
199     defer allPoolsMu.Unlock()
200     pid := runtime_procPin()
201     // poolCleanup won't be called while we are pinned.
202     s := p.localSize
203     l := p.local
204     if uintptr(pid) < s {
205         return indexLocal(l, pid) //【标注点6】
206     }
207     if p.local == nil { //【标注点4】
208         allPools = append(allPools, p) 
209     }
210     // If GOMAXPROCS changes between GCs, we re-allocate the array and lose the old one.
211     size := runtime.GOMAXPROCS(0) //【标注点5】
212     local := make([]poolLocal, size)
213     atomic.StorePointer(&p.local, unsafe.Pointer(&local[0])) // store-release
214     atomic.StoreUintptr(&p.localSize, uintptr(size))         // store-release
215     return &local[pid]
216 }
```
刚开始Pool是没有进行初始化的，先看pinSlow如何初始化的，【标注点4】开始，如果获取local为nil，表明未初始化（也有可能被GC过），需要首先初始化。接着【标注点5】，先获取当前设置的GOMAXPROCS的值（P的数量），创建对应数量的poolLocal，Pool.local指向这段创建的内存，更新Pool.localSize为P的数量，返回当前p对应的那个poolLocal，pid是runtime_procPin返回的。再看【标注点6】。

```
250 func indexLocal(l unsafe.Pointer, i int) *poolLocal {
251     lp := unsafe.Pointer(uintptr(l) + uintptr(i)*unsafe.Sizeof(poolLocal{}))
252     return (*poolLocal)(lp)
253 }
```
如果localSize被初始化，且P的index在合理值范围，则通过偏移量找到对应的poolLocal。

总结一下pinSlow： runtime_procPin找到当前P的index，如果第一次则创建所有的poolLocal，把当前创建的Pool加入到全局的`allPools   []*Pool`（在一个进程中多处使用sync.Pool,统一有allPools管理），创建连续的poolLocal，每个P一个poolLocal，每个P通过index访问对应的poolLocal。

回到pin(), 通过runtime_procPin拿到g绑定的P的index（pid),查询P的poolLocal，如果没有调用pinSlow进行创建，最后返回对应的poolLocal，pin保证最后肯定能够返回一个有效的poolLocal。
***
*特别强调*：需要特别注意pin和pinSlow中间有release-acquire的语义，186，187和213，214行的顺序非常重要。
pin和pinSlow并发执行，pin中能够读到最新的localSize，而release之前pinSlow的相关操作，在pin中是可见的，包括对p.local的赋值，这也是为什么要先读取localSize，再使用local（186，187行）
195到200行表明要想使用全局的mutex，则P必须是可抢占的，加锁后再重新不可抢占。 （TODO需要以后补充）
***

#### 2.2.3 sync::Get
看完pin有点心累，回到Get继续看吧(128行)，如果当前的private没有被使用，则置空private返回x。如果private已经被使用还没有还回来（Put）,则从当前poolLocal中的shared中选取一个，需要加锁，因为是共享的。如果当前的shared也是空的，则需要顺序遍历从相邻的poolLocal的shared中，直到找到一个，这就是getSlow的实现。

最后如果都找不到，则通过New创建一个新的返回，所以，从这里看到：首先使用private，private被使用了，则使用自己的shared中的，如果还没有那就顺序遍历相邻的poolLocal中的shared，如果目前还没有那就只能New了，复用的意义就体现在这里。New可能会被多次调用，多余的New的出来的，Put的时候会放到shared中，下面会讲到。

整个底层数据结构如下图所示。

[pool](https://raw.githubusercontent.com/GenuineJyn/GenuineJyn.github.io/master/pictures/pool.png)

### 2.3 sync::Put
有取又换，来看一下Put，代码如下。
先看100行，这里pin肯定返回一个有效的poolLocal，但是需要特别注意：返回的poolLocal可能跟Get的时候可能不是同一个poolLocal，因为这期间可能发生过GC，pin会重新创建的，这是有可能的，需要回去仔细去品味一下pin的，不管怎样，这里返回一个有效的poolLocal，如果private为空，则刚好还到这里，如果已经有值了，则需要返回到shared上。因为要加锁，则必须被抢占：runtime_procUnpin。

```
 88 func (p *Pool) Put(x interface{}) {
 89     if x == nil {
 90         return
 91     }
 92     if race.Enabled {
 93         if fastrand()%4 == 0 {
 94             // Randomly drop x on floor.
 95             return
 96         }
 97         race.ReleaseMerge(poolRaceAddr(x))
 98         race.Disable()
 99     }
100     l := p.pin()
101     if l.private == nil {
102         l.private = x
103         x = nil
104     }
105     runtime_procUnpin()
106     if x != nil {
107         l.Lock()
108         l.shared = append(l.shared, x)
109         l.Unlock()
110     }
111     if race.Enabled {
112         race.Enable()
113     }
114 }
```

### 2.5 为什么减轻了GC的压力？
先看看poolCleanup()实现，从全局的allPools依次清理，思路比较清晰。

```
218 func poolCleanup() {
219     // This function is called with the world stopped, at the beginning of a garbage collection.
220     // It must not allocate and probably should not call any runtime functions.
221     // Defensively zero out everything, 2 reasons:
222     // 1. To prevent false retention of whole Pools.
223     // 2. If GC happens while a goroutine works with l.shared in Put/Get,
224     //    it will retain whole Pool. So next cycle memory consumption would be doubled.
225     for i, p := range allPools {
226         allPools[i] = nil
227         for i := 0; i < int(p.localSize); i++ {
228             l := indexLocal(p.local, i)
229             l.private = nil
230             for j := range l.shared {
231                 l.shared[j] = nil
232             }
233             l.shared = nil
234         }
235         p.local = nil
236         p.localSize = 0
237     }
238     allPools = []*Pool{}
239 }
```
poolCleanup在init中被注册,如下。

```
246 func init() {
247     runtime_registerPoolCleanup(poolCleanup)
248 }
```

```
// runtime/mgc.go
2171 //go:linkname sync_runtime_registerPoolCleanup sync.runtime_registerPoolCleanup
2172 func sync_runtime_registerPoolCleanup(f func()) {
2173     poolcleanup = f
2174 }
2175
2176 func clearpools() {
2177     // clear sync.Pools
2178     if poolcleanup != nil {
2179         poolcleanup()
2180     }
```
那什么时候能够被调用么？那就找找clearpools什么时候会被调用，继续找。

```
1199 func gcStart(trigger gcTrigger) {
1200     // Since this is called from malloc and malloc is called in
1201     // the guts of a number of libraries that might be holding
1202     // locks, don't attempt to start GC in non-preemptible or
1203     // potentially unstable situations.
1204     mp := acquirem()
1205     if gp := getg(); gp == mp.g0 || mp.locks > 1 || mp.preemptoff != "" {
1206         releasem(mp)
1207         return
1208     }
	......
1289     // clearpools before we start the GC. If we wait they memory will not be
1290     // reclaimed until the next GC cycle.
1291     clearpools()
```
每次GC开始的时候，但是需要1205行, 这里mp.locks > 1的时候直接返回了, 注释中说明：其他库可能持有locks，不要在非抢占和潜在的不稳定的状态下尝试启动GC，结合223行的注释，在Get和Put操作l.shared的时候不会进行GC（这里需要搞清楚Mutex.Lock()做了什么？）另外执行pin的时候都会持有锁这时候也是不会进行GC的，这都能减少GC的次数，这两次GC之间可以复用对象。

## 参考文档

* [go-scheduler](https://morsmachine.dk/go-scheduler)
*  [Scalable Go Scheduler Design Doc](https://docs.google.com/document/d/1TTj4T2JO42uD5ID9e89oa0sLKhJYD0Y_kqxDv3I3XMw/edit)
* [scheduling-in-go](https://www.ardanlabs.com/blog/2018/08/scheduling-in-go-part2.html)
* [race-detector](https://blog.golang.org/race-detector)
* [【go:linkname】](https://golang.org/cmd/compile/#hdr-Compiler_Directives)
* [【go:linkname issue】](https://github.com/golang/go/issues/15006)
* [order of evaluation](https://en.cppreference.com/w/cpp/language/eval_order)
* [memory order](https://en.cppreference.com/w/cpp/atomic/memory_order)
* [acquire-and-release-semantics](http://preshing.com/20120913/acquire-and-release-semantics/)
* [False Sharing](https://mechanical-sympathy.blogspot.com/2011/07/false-sharing.html)
* [CPU Caches and Why You Care](https://www.aristeia.com/TalkNotes/codedive-CPUCachesHandouts.pdf)